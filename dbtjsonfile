from pyspark.sql import SparkSession

# Root path pointing exactly to the table (not metadata or data)
iceberg_table_path = "s3://app-id-90177-dep-id-114232-uu-id-pee895fr5knp/105130_tpc_products"

spark = (
    SparkSession.builder
    .appName("IcebergPathReadTest")
    .config("spark.sql.catalog.local", "org.apache.iceberg.spark.SparkCatalog")
    .config("spark.sql.catalog.local.type", "hadoop")
    .config("spark.sql.catalog.local.warehouse", "s3://app-id-90177-dep-id-114232-uu-id-pee895fr5knp/")
    .getOrCreate()
)

print("✅ Spark session started.")

try:
    df = spark.read.format("iceberg").load(iceberg_table_path)
    df.show(5)
    print("✅ Table read success.")
except Exception as e:
    print("❌ Iceberg path-based read failed.")
    print(str(e))

spark.stop()
