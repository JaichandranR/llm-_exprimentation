import boto3
import pandas as pd
import io
from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ConnectTimeoutError, ClientError

def assume_role(role_arn, session_name):
    """ Assume a cross-account IAM role and return temporary credentials. """
    sts_client = boto3.client("sts")
    response = sts_client.assume_role(RoleArn=role_arn, RoleSessionName=session_name)
    return response["Credentials"]

def get_table_s3_location(glue_client, database_name, table_name, catalog_id):
    """ Retrieve the S3 location of the Glue table. """
    table = glue_client.get_table(DatabaseName=database_name, Name=table_name, CatalogId=catalog_id)
    return table["Table"]["StorageDescriptor"]["Location"]

def read_s3_file(s3_client, bucket, key, num_rows=10):
    """ Read first 'num_rows' lines from a file in S3. """
    response = s3_client.get_object(Bucket=bucket, Key=key)
    file_content = response["Body"].read().decode("utf-8")
    
    # Convert to pandas dataframe and print first 10 rows
    df = pd.read_csv(io.StringIO(file_content))
    print(df.head(num_rows))

def fetch_table_data(role_arn, session_name, region_name, database_name, table_name, catalog_id):
    try:
        # Assume role to access cross-account resources
        credentials = assume_role(role_arn, session_name)
        
        # Create Glue & S3 clients with assumed role credentials
        glue_client = boto3.client(
            "glue", region_name=region_name,
            aws_access_key_id=credentials["AccessKeyId"],
            aws_secret_access_key=credentials["SecretAccessKey"],
            aws_session_token=credentials["SessionToken"]
        )

        s3_client = boto3.client(
            "s3", region_name=region_name,
            aws_access_key_id=credentials["AccessKeyId"],
            aws_secret_access_key=credentials["SecretAccessKey"],
            aws_session_token=credentials["SessionToken"]
        )

        # Get S3 location of the table
        s3_path = get_table_s3_location(glue_client, database_name, table_name, catalog_id)
        print(f"S3 Location of {table_name}: {s3_path}")

        # Extract bucket name and key prefix from S3 path
        s3_path = s3_path.replace("s3://", "")
        bucket_name, key_prefix = s3_path.split("/", 1)

        # List objects in the S3 path
        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=key_prefix)
        if "Contents" not in response:
            print("No files found in the table's S3 location.")
            return
        
        # Get the first file and read first 10 rows
        first_file_key = response["Contents"][0]["Key"]
        print(f"Reading first 10 rows from: s3://{bucket_name}/{first_file_key}")
        read_s3_file(s3_client, bucket_name, first_file_key, num_rows=10)

    except NoCredentialsError:
        print("AWS credentials not found. Please configure your credentials.")
    except PartialCredentialsError:
        print("Incomplete AWS credentials. Please check your configuration.")
    except ConnectTimeoutError:
        print("Connection timed out. Please check your network connectivity.")
    except ClientError as e:
        print(f"Client error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

def main():
    role_arn = "arn:aws:iam::691272445312:role/lancholers/services/AWSGlueServiceRole-90177-tf"
    session_name = "GlueJobRunnerSession-123"
    region_name = "us-east-1"
    database_name = "common_data_dev"
    table_name = "87674_verum_application"
    catalog_id = "809616259930"

    fetch_table_data(role_arn, session_name, region_name, database_name, table_name, catalog_id)

if __name__ == "__main__":
    main()
