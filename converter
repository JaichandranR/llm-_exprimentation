from pyspark.sql import SparkSession

# Configurable parameters
catalog_nm = "cosmos_nonhcd_iceberg"
warehouse_path = "s3://app-id-90177-dep-id-114232-uu-id-pee895fr5knp/105130_tpc_products/"
db_name = "common_data"
table_name = "105130_tpc_products"

# Compose full table name
full_table_path = f"{catalog_nm}.{db_name}.{table_name}"

try:
    # Start Spark session with Iceberg config
    spark = (
        SparkSession.builder
        .appName("IcebergPropertyUpdatePOC")
        .config(f"spark.sql.catalog.{catalog_nm}", "org.apache.iceberg.spark.SparkCatalog")
        .config(f"spark.sql.catalog.{catalog_nm}.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog")
        .config(f"spark.sql.catalog.{catalog_nm}.io-impl", "org.apache.iceberg.aws.s3.S3FileIO")
        .config(f"spark.sql.catalog.{catalog_nm}.warehouse", warehouse_path)
        .getOrCreate()
    )

    print("‚úÖ Spark session created successfully.")

    # Print loaded JARs for debugging
    try:
        jars = spark.sparkContext._jsc.hadoopConfiguration().get("spark.jars")
        print(f"üì¶ JARs loaded into Spark: {jars}")
    except Exception as jex:
        print(f"‚ö†Ô∏è Could not retrieve JAR paths: {str(jex)}")

    # Read Iceberg table
    df = spark.read.format("iceberg").load(full_table_path)
    df.show(5)
    print("‚úÖ Iceberg table read successfully.")

    # Update table property
    spark.sql(
        f"""
        ALTER TABLE {full_table_path}
        SET TBLPROPERTIES ('write.metadata.relative-path' = 'true')
        """
    )
    print(f"‚úÖ Successfully updated table property for {full_table_path}")

except Exception as e:
    print("‚ùå Failed to update Iceberg table.")
    print(str(e))

finally:
    spark.stop()
