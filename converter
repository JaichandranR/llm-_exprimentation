import time
from transformers import AutoModel, AutoTokenizer

# Specify the path to the model's directory, NOT the .bin file directly
bin_model_path = "./downloaded_models/all-mpnet-base-v2"  # Path to the folder containing the .bin file and config.json

# Log start time
start_time = time.time()
print(f"Starting the model conversion process...")

# Step 1: Load the model and tokenizer
try:
    print(f"Loading the model and tokenizer from: {bin_model_path}")
    load_start = time.time()
    model = AutoModel.from_pretrained(bin_model_path)
    tokenizer = AutoTokenizer.from_pretrained(bin_model_path)
    print(f"Model and tokenizer loaded successfully in {time.time() - load_start:.2f} seconds.")
except Exception as e:
    print(f"Error loading model or tokenizer: {e}")
    exit()

# Step 2: Save the model in the safetensors format
safetensors_model_path = "./downloaded_models/all-mpnet-base-v2-safetensors"  # Path to save the safetensors model
try:
    print(f"Saving the model in safetensors format to: {safetensors_model_path}")
    save_start = time.time()
    model.save_pretrained(safetensors_model_path, safe_serialization=True)
    tokenizer.save_pretrained(safetensors_model_path)
    print(f"Model and tokenizer saved successfully in {time.time() - save_start:.2f} seconds.")
except Exception as e:
    print(f"Error saving model in safetensors format: {e}")

# Log end time
end_time = time.time()
print(f"Total time for the process: {end_time - start_time:.2f} seconds.")
