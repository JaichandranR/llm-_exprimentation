from pyspark.sql import SparkSession
import sys
from awsglue.utils import getResolvedOptions

args = getResolvedOptions(sys.argv, [
    'catalog_nm',
    'output_bucket',
    'database_nm',
    'table_nm'
])

catalog_nm    = args['catalog_nm']
output_bucket = args['output_bucket']
database_nm   = args['database_nm']
table_nm      = args['table_nm']

# Start SparkSession with Iceberg config
spark = (
    SparkSession.builder
    .appName("IcebergReadPOC")
    .config(f"spark.sql.catalog.{catalog_nm}", "org.apache.iceberg.spark.SparkCatalog")
    .config(f"spark.sql.catalog.{catalog_nm}.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog")
    .config(f"spark.sql.catalog.{catalog_nm}.io-impl", "org.apache.iceberg.aws.s3.S3FileIO")
    .config(f"spark.sql.catalog.{catalog_nm}.warehouse", output_bucket)
    .getOrCreate()
)

# Attempt to read from Iceberg table
try:
    full_table = f"{catalog_nm}.{database_nm}.{table_nm}"
    df = spark.sql(f"SELECT * FROM {full_table} LIMIT 10")
    df.show()
    print("✅ Successfully read Iceberg table.")
except Exception as e:
    print(f"❌ Failed to read Iceberg table: {e}")
    sys.exit(1)
finally:
    spark.stop()
