import sys
import boto3
from datetime import datetime
from awsglue.utils import getResolvedOptions
from pyspark.sql import SparkSession

# Read input arguments
args = getResolvedOptions(sys.argv, [
    'catalog_nm',
    'output_bucket',
    'database_nm',
    'table_nm'
])

catalog_nm   = args['catalog_nm']
output_bucket = args['output_bucket']
db_name      = args['database_nm']
table_name   = args['table_nm']

# Start Spark session with Iceberg config
spark = (
    SparkSession.builder
    .appName("IcebergPropertyUpdatePOC")
    .config(f"spark.sql.catalog.{catalog_nm}", "org.apache.iceberg.spark.SparkCatalog")
    .config(f"spark.sql.catalog.{catalog_nm}.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog")
    .config(f"spark.sql.catalog.{catalog_nm}.io-impl", "org.apache.iceberg.aws.s3.S3FileIO")
    .config(f"spark.sql.catalog.{catalog_nm}.warehouse", output_bucket)
    .getOrCreate()
)

# Run ALTER TABLE to set relative metadata path
try:
    full_table = f"{catalog_nm}.{db_name}.{table_name}"
    alter_sql = f"""
        ALTER TABLE {full_table}
        SET TBLPROPERTIES ('write.metadata.relative-path' = 'true')
    """
    print(f"Running SQL: {alter_sql}")
    spark.sql(alter_sql)
    print(f"✅ Successfully updated table: {full_table}")
except Exception as e:
    print(f"❌ Failed to update Iceberg table property: {e}")
    sys.exit(1)
finally:
    spark.stop()
