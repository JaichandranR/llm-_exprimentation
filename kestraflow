from datetime import datetime, timedelta
from pyspark.sql import SparkSession

# ─── CONFIG ───────────────────────────────────────────────────────────────────
CATALOG       = "cosmos_nonhcd_iceberg"
DATABASE      = "common_data"
TABLE         = "metadata_table"
RETENTION_DAYS = 7

# ─── SPARK SETUP ───────────────────────────────────────────────────────────────
spark = (
    SparkSession.builder
      .appName("Iceberg_ExpireSnapshots_Proc")
      .config(f"spark.sql.catalog.{CATALOG}",              "org.apache.iceberg.spark.SparkCatalog")
      .config(f"spark.sql.catalog.{CATALOG}.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog")
      .config(f"spark.sql.catalog.{CATALOG}.io-impl",      "org.apache.iceberg.aws.s3.S3FileIO")
      .config("spark.sql.extensions",                      "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions")
      .enableHiveSupport()
      .getOrCreate()
)

# ─── 1) Compute the timestamp 7 days ago ─────────────────────────────────────
cutoff_ts = (datetime.utcnow() - timedelta(days=RETENTION_DAYS)) \
               .strftime("%Y-%m-%d %H:%M:%S")

print(f"Calling system.expire_snapshots on {DATABASE}.{TABLE} older than {cutoff_ts} UTC")

# ─── 2) Call the Iceberg expire_snapshots procedure ─────────────────────────
sql = f"""
CALL {CATALOG}.system.expire_snapshots(
  table => '{DATABASE}.{TABLE}',
  older_than => TIMESTAMP '{cutoff_ts}'
)
"""
spark.sql(sql)

print("✅ expire_snapshots procedure completed.")
spark.stop()
