from pyspark.sql import SparkSession
# … set up SparkSession with Iceberg + GlueCatalog …
table_s3a = "s3a://correct-bucket/correct-table-path"
tbl = spark._jvm.org.apache.iceberg.hadoop.HadoopTables().load(table_s3a)
tbl.expireSnapshots().expireOlderThan(cutoffMs).commit()
