from datetime import datetime, timedelta
from pyspark.sql import SparkSession

# ─── CONFIG ───────────────────────────────────────────────────────────────────
CATALOG         = "cosmos_nonhcd_iceberg"
DATABASE        = "common_data"
TABLE           = "metadata_table"
WAREHOUSE       = "s3://app-id-90177-dep-id-114232-uu-id-pee895Fr5knp/"
RETENTION_DAYS  = 7

# ─── BOOTSTRAP SPARK ───────────────────────────────────────────────────────────
spark = (
    SparkSession.builder
      .appName("Iceberg_Actions_ExpireSnapshots")
      .config(f"spark.sql.catalog.{CATALOG}",              "org.apache.iceberg.spark.SparkCatalog")
      .config(f"spark.sql.catalog.{CATALOG}.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog")
      .config(f"spark.sql.catalog.{CATALOG}.io-impl",      "org.apache.iceberg.aws.s3.S3FileIO")
      .config(f"spark.sql.catalog.{CATALOG}.warehouse",    WAREHOUSE)
      .config("spark.sql.extensions",                      "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions")
      .enableHiveSupport()
      .getOrCreate()
)

# ─── COMPUTE CUTOFF ───────────────────────────────────────────────────────────
cutoff_ms = int((datetime.utcnow() - timedelta(days=RETENTION_DAYS)).timestamp() * 1000)
print(f"Expiring all snapshots older than {RETENTION_DAYS} days (<{cutoff_ms}ms)...")

# ─── INVOKE ICEBERG ACTIONS API ────────────────────────────────────────────────
full_table = f"{CATALOG}.{DATABASE}.{TABLE}"
jvm         = spark._jvm
Actions     = jvm.org.apache.iceberg.actions.Actions

( Actions
    .forTable(spark._jsparkSession, full_table)
    .expireSnapshots()
      .expireOlderThan(cutoff_ms)
    .execute()
)

print("✅ expireSnapshots action completed.")
spark.stop()
