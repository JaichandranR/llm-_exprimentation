def test_get_backlog_partition_hours_filters_correctly(self):
    with patch("builtins.print") as mock_print:
        iceberg_compaction.args = {
            'catalog_nm': 'test_catalog',
            'table_nm': 'test_table',
            'source_db': 'test_db',
            'expire_snapshots_day': '7',
            'skip_newest_partitions': '0'
        }

        mock_df = MagicMock()
        self.mock_spark.table.return_value = mock_df

        mock_df.select.return_value = mock_df
        mock_df.filter.return_value = mock_df
        mock_df.withColumn.return_value = mock_df
        mock_df.distinct.return_value = mock_df
        mock_df.schema.fields = []  # Simulate required schema

        # Simulate column filtering conditions
        mock_col = MagicMock()
        mock_df.__getitem__.return_value = mock_col
        mock_col.__ge__.return_value = True
        mock_col.__lt__.return_value = True

        # Patch df.first() to return expected compacted hour
        from types import SimpleNamespace
        mock_df.first.return_value = SimpleNamespace(last_compacted_hour=485760)

        # Trigger the function
        hours = iceberg_compaction.get_backlog_partition_hours()

        # Check if filtering logic was invoked
        self.assertTrue(mock_df.filter.called)
        self.assertIsInstance(hours, list)
