import os
import json
import yaml
import logging
import subprocess
import pandas as pd
from datetime import datetime

from trino.dbapi import connect
from trino.auth import JWTAuthentication


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)


# ============================================================
# 1. Load dbt profiles.yml and connect to Trino
# ============================================================
def load_dbt_trino_profile(profile_path, profile_name, target_name):
    profile_path = os.path.expanduser(profile_path)

    if not os.path.exists(profile_path):
        raise FileNotFoundError(f"profiles.yml not found at {profile_path}")

    with open(profile_path, "r") as f:
        profiles = yaml.safe_load(f)

    if profile_name not in profiles:
        raise KeyError(f"Profile '{profile_name}' not found")

    profile = profiles[profile_name]["outputs"][target_name]

    # Load JWT token
    base = os.path.dirname(profile_path)
    token_file = "sit_token.txt" if target_name != "prototype" else "prod_token.txt"
    jwt_path = os.path.join(base, "lib", "jwt", token_file)

    if not os.path.exists(jwt_path):
        raise FileNotFoundError(f"JWT token file not found at {jwt_path}")

    with open(jwt_path, "r") as f:
        jwt_token = f.read().strip()

    auth = JWTAuthentication(jwt_token)

    conn = connect(
        host=profile["host"],
        port=profile["port"],
        catalog=profile["catalog"],
        schema=profile["schema"],
        user=None,
        http_scheme=profile.get("http_scheme", "https"),
        auth=auth,
    )

    logging.info("Connected to Trino successfully.")
    return conn, profile["catalog"], profile["schema"]


# ============================================================
# 2. Fetch manifest.json via curl
# ============================================================
def fetch_manifest(team_name, out_dir):
    out_path = os.path.join(out_dir, f"manifest_{team_name}.json")

    url = (
        "https://cronos-cao-app2app.prod.aws.jpmchase.net/"
        f"git-webhook-consumer/defer-manifest?teamName={team_name}"
    )

    result = subprocess.run(
        ["curl", "-s", "-o", out_path, "-X", "GET", url],
        capture_output=True
    )

    if result.returncode != 0:
        logging.error(f"Failed to fetch manifest for {team_name}: {result.stderr.decode()}")
        return None

    if not os.path.exists(out_path) or os.path.getsize(out_path) == 0:
        logging.warning(f"Manifest for {team_name} is empty.")
        return None

    logging.info(f"Fetched manifest for {team_name}")
    return out_path


# ============================================================
# 3. Build global registry for all models/sources
# ============================================================
def build_registry(manifest_paths):
    registry = {}

    for mpath in manifest_paths:
        with open(mpath, "r") as f:
            manifest = json.load(f)

        project = manifest["metadata"]["project_name"]

        # Models
        for _, node in manifest.get("nodes", {}).items():
            if node["resource_type"] == "model":
                name = node["name"].lower()
                registry[name] = {
                    "project": project,
                    "schema": node.get("schema"),
                    "fqn": node.get("fqn"),
                    "type": "model"
                }

        # Sources
        for _, src in manifest.get("sources", {}).items():
            name = src["name"].lower()
            registry[name] = {
                "project": project,
                "schema": src.get("schema"),
                "fqn": src.get("fqn"),
                "type": "source"
            }

    logging.info(f"Registry built with {len(registry)} entries.")
    return registry


# ============================================================
# 4. Parse parent-child dependencies (ref + source)
# ============================================================
def parse_dependencies(manifest_paths, registry):
    records = []

    for mpath in manifest_paths:
        with open(mpath, "r") as f:
            manifest = json.load(f)

        child_project = manifest["metadata"]["project_name"]

        for _, node in manifest["nodes"].items():
            if node["resource_type"] != "model":
                continue

            child_name = node["name"].lower()
            child_schema = node["schema"]
            child_fqn = ".".join(node["fqn"])
            ts = datetime.now().isoformat()

            # ---------------------------------------------------
            # A) ref() dependencies
            # ---------------------------------------------------
            for pid in node.get("depends_on", {}).get("nodes", []):
                parent_name = manifest["nodes"].get(pid, {}).get("name")
                if not parent_name:
                    continue

                parent_info = registry.get(parent_name.lower())
                if not parent_info:
                    logging.warning(f"Missing parent info for model {parent_name}")
                    continue

                records.append({
                    "parent_model": parent_name,
                    "parent_project": parent_info["project"],
                    "parent_schema": parent_info["schema"],
                    "child_model": child_name,
                    "child_project": child_project,
                    "child_schema": child_schema,
                    "relation_type": "ref",
                    "parent_fqn": ".".join(parent_info["fqn"]),
                    "child_fqn": child_fqn,
                    "timestamp": ts
                })

            # ---------------------------------------------------
            # B) source() dependencies
            # ---------------------------------------------------
            for sid in node.get("depends_on", {}).get("sources", []):
                source_name = manifest["sources"][sid]["name"]
                parent_info = registry.get(source_name.lower())

                if not parent_info:
                    logging.warning(f"Missing parent info for source {source_name}")
                    continue

                records.append({
                    "parent_model": source_name,
                    "parent_project": parent_info["project"],
                    "parent_schema": parent_info["schema"],
                    "child_model": child_name,
                    "child_project": child_project,
                    "child_schema": child_schema,
                    "relation_type": "source",
                    "parent_fqn": ".".join(parent_info["fqn"]),
                    "child_fqn": child_fqn,
                    "timestamp": ts
                })

    df = pd.DataFrame(records)
    logging.info(f"Parsed {len(df)} dependency records.")
    return df


# ============================================================
# 5. Create lineage table in Trino (idempotent)
# ============================================================
def create_lineage_table(cursor, catalog, schema, table):
    sql = f"""
    CREATE TABLE IF NOT EXISTS {catalog}.{schema}.{table} (
        parent_model VARCHAR,
        parent_project VARCHAR,
        parent_schema VARCHAR,
        child_model VARCHAR,
        child_project VARCHAR,
        child_schema VARCHAR,
        relation_type VARCHAR,
        parent_fqn VARCHAR,
        child_fqn VARCHAR,
        timestamp VARCHAR
    )
    """
    cursor.execute(sql)
    logging.info(f"Ensured table {table} exists.")


# ============================================================
# 6. Incremental MERGE Insert Logic
# ============================================================
def merge_records(cursor, catalog, schema, table, df):
    for _, row in df.iterrows():
        sql = f"""
        INSERT INTO {catalog}.{schema}.{table}
        (
            parent_model, parent_project, parent_schema,
            child_model, child_project, child_schema,
            relation_type, parent_fqn, child_fqn, timestamp
        )
        VALUES (
            '{row.parent_model}', '{row.parent_project}', '{row.parent_schema}',
            '{row.child_model}', '{row.child_project}', '{row.child_schema}',
            '{row.relation_type}', '{row.parent_fqn}', '{row.child_fqn}',
            '{row.timestamp}'
        )
        ON CONFLICT (parent_fqn, child_fqn, relation_type)
        DO NOTHING
        """
        cursor.execute(sql)

    logging.info("Incremental MERGE completed.")


# ============================================================
# 7. MAIN WORKFLOW
# ============================================================
if __name__ == "__main__":

    # ----------------------------
    # Read team list externally
    # ----------------------------
    with open("teams.txt", "r") as f:
        TEAMS = [t.strip() for t in f.readlines()]

    OUT_DIR = "manifests"
    os.makedirs(OUT_DIR, exist_ok=True)

    manifest_paths = []

    # Pull manifests
    for team in TEAMS:
        path = fetch_manifest(team, OUT_DIR)
        if path:
            manifest_paths.append(path)

    # Build registry + dependencies
    registry = build_registry(manifest_paths)
    df = parse_dependencies(manifest_paths, registry)

    # Connect to Trino using your profiles.yml
    conn, catalog, schema = load_dbt_trino_profile(
        profile_path="C:/Users/.../profiles.yml",
        profile_name="dbt-trino-cosmos",
        target_name="prototype"
    )
    cursor = conn.cursor()

    # Create table if not exists
    table_name = "global_lineage_purge_engine"
    create_lineage_table(cursor, catalog, schema, table_name)

    # Incremental insert
    merge_records(cursor, catalog, schema, table_name, df)

    logging.info("All manifests processed and lineage table populated.")
