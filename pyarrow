import boto3
import pyarrow.parquet as pq
import io

def list_s3_objects(bucket_name, prefix):
    """ List objects in an S3 bucket under a given prefix """
    s3_client = boto3.client('s3')
    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

    if 'Contents' in response:
        files = [obj['Key'] for obj in response['Contents']]
        print(f"\n‚úÖ Found {len(files)} files in S3 path {prefix}:")
        for file in files[:5]:  # Show first 5 files
            print(f" - {file}")
        return files
    else:
        print("\n‚ùå No files found in S3 path.")
        return []

def read_parquet_from_s3(bucket_name, parquet_file):
    """ Read first 10 rows from a Parquet file in S3 """
    s3_client = boto3.client('s3')

    try:
        obj = s3_client.get_object(Bucket=bucket_name, Key=parquet_file)
        parquet_data = pq.read_table(io.BytesIO(obj['Body'].read()))

        print("\nüìå First 10 rows from Parquet file:")
        print(parquet_data.to_pandas().head(10))  # Show as Pandas DataFrame
    except Exception as e:
        print(f"[ERROR] Failed to read Parquet file: {str(e)}")

def main():
    bucket_name = "your-glue-warehouse-bucket"
    table_prefix = "87674_verum_application/data/"  # Iceberg data location

    # Step 1: List Parquet files in S3
    files = list_s3_objects(bucket_name, table_prefix)

    if files:
        # Step 2: Read first 10 rows from the first Parquet file
        read_parquet_from_s3(bucket_name, files[0])

if __name__ == "__main__":
    main()
