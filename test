import unittest
from unittest.mock import patch, MagicMock
from src.main.python import iceberg_compaction

class TestBacklogPartitionHours(unittest.TestCase):

    def test_backlog_partition_hours_with_gte_filter(self):
        # Prepare mock DataFrame
        data = {
            "time_hour_val": [485759, 485760, 485761, 485762, 485763],
            "other_col": [1, 2, 3, 4, 5]
        }

        class MockDF:
            def __init__(self, data):
                import pandas as pd
                self.df = pd.DataFrame(data)

            def filter(self, cond):
                return self

            def select(self, *cols):
                return self

            def distinct(self):
                return self

            def orderBy(self, col):
                return self

            def limit(self, n):
                return self

            def rdd(self):
                return self.df[["time_hour_val"]].itertuples(index=False, name=None)

        mock_df = MockDF(data)

        with patch('src.main.python.iceberg_compaction.SparkSession.table', return_value=mock_df):
            with patch('src.main.python.iceberg_compaction.get_current_hour', return_value=485764):
                result = iceberg_compaction.get_backlog_partition_hours(
                    spark=MagicMock(),
                    full_table="test_table",
                    partition_cols=["time_hour"],
                    last_hour_done=485760,
                    current_hour=485764,
                    max_backlog_partitions=10
                )

        expected = [485760, 485761, 485762, 485763]  # all >= 485760 and < 485764
        self.assertEqual(result, expected)

if __name__ == '__main__':
    unittest.main()
